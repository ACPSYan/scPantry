from pathlib import Path
from gtfparse import read_gtf
import numpy as np
import pandas as pd
import pantry

def load_fastq_map(map_file: Path, fastq_dir: Path, paired_end) -> dict:
    """Load the FASTQ file paths for each sample.

    If paired_end is True, each dictionary value is a tuple of two lists of
    paths, otherwise each value is a list of paths.
    """
    paths = {}
    with open(map_file, 'r') as f:
        for line in f.read().splitlines():
            if paired_end:
                fastq1, fastq2, sample_id = line.split('\t')
                if sample_id not in paths:
                    paths[sample_id] = ([], [])
                paths[sample_id][0].append(str(fastq_dir / fastq1))
                paths[sample_id][1].append(str(fastq_dir / fastq2))
            else:
                fastq, sample_id = line.split('\t')
                if sample_id not in paths:
                    paths[sample_id] = []
                paths[sample_id].append(str(fastq_dir / fastq))
    return paths

def new_fastq_map(samples: list, fastq_dir: Path, paired_end: bool) -> dict:
    """Get the list(s) of FASTQ file paths to be created.
    
    This is used when FASTQ files are produced from input BAM files.
    If paired_end is True, each dictionary value is a tuple of two lists of
    paths, otherwise each value is a list of paths.
    """
    paths = {}
    for sample_id in samples:
        if paired_end:
            paths[sample_id] = ([], [])
            paths[sample_id][0].append(fastq_dir / f'{sample_id}.PE1.fastq.gz')
            paths[sample_id][1].append(fastq_dir / f'{sample_id}.PE2.fastq.gz')
        else:
            paths[sample_id] = [fastq_dir / f'{sample_id}.SE.fastq.gz']
    return paths

def load_bam_map(map_file: Path, bam_dir: Path) -> dict:
    """Load the BAM file path for each sample."""
    paths = {}
    with open(map_file, 'r') as f:
        for line in f.read().splitlines():
            bam, sample_id = line.split('\t')
            assert sample_id not in paths, "Only one BAM file allowed per sample."
            paths[sample_id] = bam_dir / bam
    return paths

def new_bam_map(samples: list, bam_dir: Path) -> dict:
    """Get the list of BAM file paths to be created.
    
    This is used when BAM files are produced from input FASTQ files using STAR.
    """
    paths = {}
    for sample_id in samples:
        paths[sample_id] = bam_dir / f'{sample_id}.Aligned.sortedByCoord.out.bam'
    return paths

def fastq_inputs(wildcards) -> list:
    """Get the list of FASTQ file paths for a sample.

    If paired_end is True, file pairs are adjacent in the list, e.g.
    [runA_1.fq.gz runA_2.fq.gz runB_1.fq.gz runB_2.fq.gz].
    """
    fastqs = fastq_map[wildcards.sample_id]
    if paired_end:
        paths = []
        for i in range(len(fastqs[0])):
            paths.append(fastqs[0][i])
            paths.append(fastqs[1][i])
        return paths
    else:
        return fastqs


configfile: 'config.yaml'

pantry.validate_config(config)

interm_dir = Path('intermediate')
ref_dir = interm_dir / 'reference'
output_dir = Path('output')

samples_file = Path(config['samples_file'])
samples = pd.read_csv(samples_file, sep='\t', header=None)[0].tolist()

paired_end = config['paired_end']
read_length = config['read_length']
if 'fastq_dir' in config:
    fastq_dir = Path(config['fastq_dir'])
    fastq_map = load_fastq_map(Path(config['fastq_map']), fastq_dir, paired_end)
else:
    fastq_dir = interm_dir / 'fastq'
    fastq_map = new_fastq_map(samples, fastq_dir, paired_end)
if 'bam_dir' in config:
    bam_dir = Path(config['bam_dir'])
    bam_map = load_bam_map(Path(config['bam_map']), bam_dir)
else:
    bam_dir = interm_dir / 'bam'
    bam_map = new_bam_map(samples, bam_dir)

ref_genome = Path(config['ref_genome'])
ref_anno = Path(config['ref_anno'])
retro_anno = Path(config['retro_anno'])
ref_cdna = Path(config['ref_cdna'])

phenotypes = config['phenotypes']
genome_size = config['genome_size'] # TODO: compute from fasta file

outputs = []
for pheno, params in phenotypes.items():
    for f in params['files']:
        outputs.append(output_dir / f)
    # Used only for QTL mapping for now:
    params['grouped'] = any(['phenotype_groups' in f for f in params['files']])

# List short steps here so they will not be submitted as cluster jobs:
# (These can be specified on a per-file basis)
localrules:
    index_bed,

# These are the target files to be generated (or regenerated if outdated):
rule all:
    input:
        outputs,
        # expand(output_dir / 'heritability' / '{pheno}_hsq.tsv', pheno=phenotypes.keys()),
        # expand(output_dir / 'qtl' / '{pheno}.cis_independent_qtl.txt.gz', pheno=phenotypes.keys()),

include: 'steps/align.smk'
for phenotype in phenotypes:
    include: f'steps/{phenotype}.smk'

rule index_bam:
    """Index a BAM file."""
    input:
        '{basename}.bam',
    output:
        '{basename}.bam.bai',
    params:
        add_threads = lambda w, threads: threads - 1,
    threads: 8
    shell:
        # It expects the number of *additional* threads to use beyond the first.
        'samtools index -@ {params.add_threads} {input}'

rule index_bed:
    """Index a BED file."""
    input:
        output_dir / '{pheno}.bed.gz',
    output:
        output_dir / '{pheno}.bed.gz.tbi'
    shell:
        'tabix {input}'

rule index_fasta:
    """Index a FASTA file, e.g. to get chromosome lengths from reference genome."""
    input:
        '{basename}.fa',
    output:
        '{basename}.fa.fai',
    shell:
        'samtools faidx {input}'
