from pathlib import Path
from gtfparse import read_gtf
import numpy as np
import pandas as pd
import pantry

configfile: 'config.yaml'

pantry.validate_config(config)
pantry.process_config(config)

interm_dir = config['intermediate_dir']
ref_dir = interm_dir / 'reference' # For newly generated reference files only
output_dir = Path('output')

samples_file = config['samples_file']
samples = config['samples']

paired_end = config['paired_end']
read_length = config['read_length']

fastq_dir = config['fastq_dir']
fastq_map = config['fastq_map']
bam_dir = config['bam_dir']
bam_map = config['bam_map']

ref_genome = config['ref_genome']
ref_anno = config['ref_anno']
retro_anno = config['retro_anno']
ref_cdna = config['ref_cdna']

phenotypes = config['phenotypes']
genome_size = config['genome_size'] # TODO: compute from fasta file

outputs = []
for pheno, params in phenotypes.items():
    for f in params['files']:
        outputs.append(output_dir / f)

# List short steps here so they will not be submitted as cluster jobs:
# (These can be specified on a per-file basis)
localrules:
    index_bed,

# These are the target files to be generated (or regenerated if outdated):
rule all:
    input:
        outputs,

## General functions used by multiple snakefiles

def fastq_inputs(wildcards) -> list:
    """Get the list of FASTQ file paths for a sample.

    This is called by several Snakemake rules to get input names.
    If paired_end is True, file pairs are adjacent in the list, e.g.
    [runA_1.fq.gz runA_2.fq.gz runB_1.fq.gz runB_2.fq.gz].
    """
    fastqs = fastq_map[wildcards.sample_id]
    if paired_end:
        paths = []
        for i in range(len(fastqs[0])):
            paths.append(fastqs[0][i])
            paths.append(fastqs[1][i])
        return paths
    else:
        return fastqs

## Load rules from all the snakefiles

include: 'steps/align.smk'
for phenotype in phenotypes:
    include: f'steps/{phenotype}.smk'

## Additional general rules

rule index_bam:
    """Index a BAM file."""
    input:
        '{basename}.bam',
    output:
        '{basename}.bam.bai',
    params:
        add_threads = lambda w, threads: threads - 1,
    threads: 8
    shell:
        # It expects the number of *additional* threads to use beyond the first.
        'samtools index -@ {params.add_threads} {input}'

rule index_bed:
    """Index a BED file."""
    input:
        output_dir / '{pheno}.bed.gz',
    output:
        output_dir / '{pheno}.bed.gz.tbi'
    shell:
        'tabix {input}'

rule index_fasta:
    """Index a FASTA file, e.g. to get chromosome lengths from reference genome."""
    input:
        '{basename}.fa',
    output:
        '{basename}.fa.fai',
    shell:
        'samtools faidx {input}'

